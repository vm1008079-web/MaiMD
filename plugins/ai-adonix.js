import fetch from 'node-fetch';

let handler = async (m, { conn, text, usedPrefix, command }) => {
  if (!text) {
    return m.reply(`ğŸ¤– *Adonix IA* ğŸ¤–\n\nUsa:\n${usedPrefix + command} [tu pregunta]\n\nEjemplo:\n${usedPrefix + command} hÃ¡blame para que te conteste en audio o haz un cÃ³digo JS que sume dos nÃºmeros`);
  }

  try {
    await m.react('ğŸ•’');

    // Detectar si quiere que le hable en audio
    const quiereAudio = /^(hÃ¡blame|hablame|voz|audio|dime|cuÃ©ntame|plÃ¡ticame|habla|dame audio)/i.test(text.trim());

    if (quiereAudio) {
      // Quitar la palabra clave para no repetirla en el texto
      let textoAudio = text.replace(/^(hÃ¡blame|hablame|voz|audio|dime|cuÃ©ntame|plÃ¡ticame|habla|dame audio)/i, '').trim();
      if (!textoAudio) textoAudio = 'QuÃ© pedo we, dime quÃ© quieres que te diga.';

      // Pedir audio a la API Loquendo con voz "Juan"
      const loquendoRes = await fetch(`https://apis-starlights-team.koyeb.app/starlight/loquendo?text=${encodeURIComponent(textoAudio)}&voice=Juan`);
      const loquendoData = await loquendoRes.json();

      if (!loquendoData.audio) {
        await m.react('âŒ');
        return m.reply('âŒ No pude generar el audio, we.');
      }

      // Enviar audio PTT (voice note) en base64 convertido a Buffer
      await conn.sendMessage(m.chat, {
        audio: Buffer.from(loquendoData.audio, 'base64'),
        mimetype: 'audio/mpeg',
        ptt: true
      }, { quoted: m });

      await m.react('âœ…');
      return;
    }

    // Si no pidiÃ³ audio, responde con texto normal desde la API Adonix
    const apiURL = `https://theadonix-api.vercel.app/api/adonix?q=${encodeURIComponent(text)}`;
    const res = await fetch(apiURL);
    const data = await res.json();

    // Si devuelve imagen
    if (data.imagen_generada) {
      await conn.sendMessage(m.chat, {
        image: { url: data.imagen_generada },
        caption: `ğŸ–¼ï¸ *Adonix IA* generÃ³ esta imagen:\n\nğŸ“Œ _${data.pregunta}_\n${data.mensaje || ''}`,
      }, { quoted: m });
      await m.react('âœ…');
      return;
    }

    // Si devuelve respuesta tipo texto
    if (data.respuesta && typeof data.respuesta === 'string') {
      const [mensaje, ...codigo] = data.respuesta.split(/```(?:javascript|js|html|)/i);
      let respuestaFinal = `ğŸŒµ *Adonix IA :*\n\n${mensaje.trim()}`;

      if (codigo.length > 0) {
        respuestaFinal += `\n\nğŸ’» *CÃ³digo:*\n\`\`\`js\n${codigo.join('```').trim().slice(0, 3900)}\n\`\`\``;
      }

      await m.reply(respuestaFinal);
      await m.react('âœ…');
      return;
    }

    // Si no trae ni imagen ni texto vÃ¡lido
    await m.react('âŒ');
    return m.reply('âŒ No se pudo procesar la respuesta de Adonix IA.');

  } catch (e) {
    console.error('[ERROR ADONIX IA]', e);
    await m.react('âŒ');
    return m.reply(`âŒ Error al usar Adonix IA:\n\n${e.message}`);
  }
};

handler.help = ['adonix <pregunta>'];
handler.tags = ['ia'];
handler.command = ['adonix', 'ai', 'adonixia'];

export default handler;
